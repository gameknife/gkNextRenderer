#version 460

#extension GL_ARB_gpu_shader_int64 : require
#extension GL_ARB_shader_clock : require

#extension GL_EXT_nonuniform_qualifier : require
#extension GL_GOOGLE_include_directive : require
//#extension GL_EXT_ray_tracing : require
#extension GL_EXT_ray_query : require

#define RQ_PIPELINE

#include "Platform.glsl"
#include "common/Heatmap.glsl"
#include "common/Material.glsl"
#include "common/UniformBufferObject.glsl"

layout(binding = 0, set = 0) uniform accelerationStructureEXT Scene;
layout(binding = 1) readonly buffer LightObjectArray { LightObject[] Lights; };
layout(binding = 3) readonly uniform UniformBufferObjectStruct { UniformBufferObject Camera; };
layout(binding = 4) readonly buffer VertexArray { float Vertices[]; };
layout(binding = 5) readonly buffer IndexArray { uint Indices[]; };
layout(binding = 6) readonly buffer MaterialArray { Material[] Materials; };
layout(binding = 7) readonly buffer OffsetArray { uvec2[] Offsets; };

layout(set = 1, binding = 0) uniform sampler2D TextureSamplers[];

layout(binding = 10, rgba32f) uniform image2D AccumulationImage;
layout(binding = 11, rg16f) uniform image2D MotionVectorImage;
layout(binding = 12, r32ui) uniform uimage2D VisibilityBuffer;
layout(binding = 13, r32ui) uniform uimage2D Visibility1Buffer;
layout(binding = 14, rgba16f) uniform image2D OutAlbedoBuffer;
layout(binding = 15, rgba16f) uniform image2D OutNormalBuffer;
layout(binding = 16, r8ui) uniform uimage2D AdaptiveSampleBuffer;
layout(binding = 17, rgba8) uniform image2D ShaderTimerBuffer;

#include "common/Const_Func.glsl"
#include "common/ColorFunc.glsl"

#include "common/RayPayload.glsl"
RayPayload Ray;
#include "common/RTCommon.glsl"

#if DESKTOP
layout(local_size_x = 8, local_size_y = 4, local_size_z = 1) in;
#else
layout(local_size_x = 32, local_size_y = 32, local_size_z = 1) in;
#endif

void main() {

    const uint64_t clock = Camera.ShowHeatmap ? clockARB() : 0;
    
    bool isEvenFrame = Camera.TotalFrames % 2 == 0;
    
    vec3 pixelColor = vec3(0);
    vec4 albedo = vec4(0);
	vec4 gbuffer = vec4(0);
	vec4 motionvector = vec4(0);
    uint primitiveId = 0;

    ivec2 iposLocal = ivec2(gl_GlobalInvocationID.xy);
    ivec2 ipos = iposLocal + ivec2(Camera.ViewportRect.x, Camera.ViewportRect.y);
    vec2 isize = vec2(Camera.ViewportRect.z, Camera.ViewportRect.w);
    
    // Ray Initialize
    Ray.RandomSeed = InitRandomSeed(gl_GlobalInvocationID.x, gl_GlobalInvocationID.y, Camera.TotalFrames);
	Ray.RandomSeed.w = Camera.RandomSeed;
    
    // Adaptive Sampling
	uint sampleTimes = Camera.NumberOfSamples;
		
	// dynamic sampleTimes;
	uint multisamplecount = 1;
	if( Camera.TotalFrames > 0 )
	{
		multisamplecount = imageLoad(AdaptiveSampleBuffer, ipos).r;
	}
	bool multisample = multisamplecount > 1;
	if(multisample)
	{
		sampleTimes = Camera.TemporalFrames / Camera.AdaptiveSteps;
	}

    #if MOBILE
        sampleTimes = 1;
    #endif
    
    for (uint s = 0; s < sampleTimes; ++s)
	{
        const vec2 pixel = vec2(iposLocal);
        vec2 uv = (pixel / isize) * 2.0 - 1.0;
        // anti aliasing
		if( Camera.TAA )
		{
			vec2 uvOffset = RandomFloat2(Ray.RandomSeed) / isize;
            uv += uvOffset;
		}
		
		vec2 offset = Camera.Aperture/2 * RandomInUnitDisk(Ray.RandomSeed);
        vec4 origin = Camera.ModelViewInverse * vec4(offset, 0, 1);
        vec4 target = Camera.ProjectionInverse * (vec4(uv.x, uv.y, 1, 1));
        vec4 direction = Camera.ModelViewInverse * vec4(normalize(target.xyz * Camera.FocusDistance - vec3(offset, 0)), 0);

        // Path Tracing
		
        vec3 rayColor = vec3(1);

	    Ray.BounceCount = 0;
        Ray.AdaptiveSample = 1;
        bool exit = GetRayColor(origin.xyz, direction.xyz, rayColor);
        if(s == 0)
        {
            FetchPrimaryRayInfo(isize, origin.xyz, direction.xyz, gbuffer, albedo, motionvector, primitiveId);
        }
        
        if(!exit)
        {
            for(uint b = 0; b < Camera.MaxNumberOfBounces; ++b)
            {	
                if( GetRayColor(origin.xyz, direction.xyz, rayColor) )
                {
                    break;
                }
            }
        }
        
        pixelColor += rayColor;

        #if !MOBILE
        if(s == 0)
        {
            // after the first spp, we could judge if reproject miss with previous primitive buffer
            vec2 prevfpos = vec2(ipos) + motionvector.rg;
            ivec2 previpos = ivec2( floor(ipos + motionvector.rg) );            
        
            if( length(motionvector.xy) > 0.01 )
            {
                uint prev_primitive_index0 = isEvenFrame ? imageLoad(Visibility1Buffer, previpos + ivec2(0, 0)).r : imageLoad(VisibilityBuffer, previpos + ivec2(0, 0)).r;
                uint prev_primitive_index1 = isEvenFrame ? imageLoad(Visibility1Buffer, previpos + ivec2(0, 1)).r : imageLoad(VisibilityBuffer, previpos + ivec2(0, 1)).r;
                uint prev_primitive_index2 = isEvenFrame ? imageLoad(Visibility1Buffer, previpos + ivec2(1, 0)).r : imageLoad(VisibilityBuffer, previpos + ivec2(1, 0)).r;
                uint prev_primitive_index3 = isEvenFrame ? imageLoad(Visibility1Buffer, previpos + ivec2(1, 1)).r : imageLoad(VisibilityBuffer, previpos + ivec2(1, 1)).r;
        
                bool miss = any(notEqual(uvec4(prev_primitive_index0, prev_primitive_index1, prev_primitive_index2, prev_primitive_index3), uvec4(primitiveId)));
        
                if (miss)
                {
                    sampleTimes = max(Camera.TemporalFrames / Camera.AdaptiveSteps, sampleTimes);
                    multisamplecount = Camera.AdaptiveSteps;
                }
            }
        }
        #endif
    }
    
    //imageStore(GBufferImage, ipos, gbuffer);
    imageStore(MotionVectorImage, ipos, motionvector);
    if(isEvenFrame)
    {
        imageStore(VisibilityBuffer, ipos, ivec4(primitiveId,0, 0, 0));
    }
    else
    {
        imageStore(Visibility1Buffer, ipos, ivec4(primitiveId,0, 0, 0));
    }
    imageStore(OutAlbedoBuffer, ipos, albedo);
    imageStore(OutNormalBuffer, ipos, gbuffer);

    // record adaptivesamplebuffer
    multisamplecount = max(1, multisamplecount - 1);
    imageStore(AdaptiveSampleBuffer, ipos, uvec4(multisamplecount));

    pixelColor = pixelColor / sampleTimes;
    imageStore(AccumulationImage, ipos, vec4(pixelColor.rgb, sampleTimes) );
    
    if (Camera.ShowHeatmap)
    {
        const uint64_t deltaTime = clockARB() - clock;
        const float heatmapScale = 1000000.0f * Camera.HeatmapScale * Camera.HeatmapScale;
        const float deltaTimeScaled = clamp(float(deltaTime) / heatmapScale, 0.0f, 1.0f);
        const vec4 shaderHeatColor = vec4(heatmap(deltaTimeScaled), 1.0);
        imageStore(ShaderTimerBuffer, ipos, shaderHeatColor );
    }
}