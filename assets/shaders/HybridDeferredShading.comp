#version 460
#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_nonuniform_qualifier : require
#extension GL_EXT_ray_query : require

#include "Platform.glsl"
#include "common/Material.glsl"
#include "common/UniformBufferObject.glsl"
#include "common/Random.glsl"
#include "common/GGXSample.glsl"

layout(binding = 0, rg32ui) uniform uimage2D MiniGBuffer0;
layout(binding = 1, rg32ui) uniform uimage2D MiniGBuffer1;
layout(binding = 2, rgba8) uniform image2D OutImage;
layout(binding = 3) readonly uniform UniformBufferObjectStruct { UniformBufferObject Camera; };
layout(binding = 4) readonly buffer VertexArray { float Vertices[]; };
layout(binding = 5) readonly buffer IndexArray { uint Indices[]; };
layout(binding = 6) readonly buffer MaterialArray { Material[] Materials; };
layout(binding = 7) readonly buffer OffsetArray { uvec2[] Offsets; };
layout(binding = 8) readonly buffer NodeProxyArray { NodeProxy[] NodeProxies; };
layout(binding = 9, rg16f) uniform image2D OutMotionVector;
layout(binding = 10, set = 0) uniform accelerationStructureEXT Scene;
layout(binding = 11, rgba16f) uniform image2D InOutDirectLight0;
layout(binding = 12, rgba16f) uniform image2D InOutDirectLight1;
layout(binding = 13, rgba16f) uniform image2D OutAlbedoBuffer;
layout(binding = 14, rgba16f) uniform image2D OutNormalBuffer;
layout(binding = 15, rgba16f) uniform image2D PrevNormalBuffer;
layout(binding = 16) buffer AmbientCubeArray { AmbientCube[] Cubes; };

layout(set = 1, binding = 0) uniform sampler2D TextureSamplers[];

#include "common/Vertex.glsl"
#include "common/Const_Func.glsl"
#include "common/equirectangularSample.glsl"

#if DESKTOP
layout(local_size_x = 8, local_size_y = 4, local_size_z = 1) in;
#else
layout(local_size_x = 32, local_size_y = 32, local_size_z = 1) in;
#endif

// Sample the ambient cube using the Half-Life 2 algorithm
vec4 sampleAmbientCubeHL2(AmbientCube cube, vec3 normal, out float occlusion) {
    vec4 color = vec4(0.0);
    color += max(normal.x, 0.0) 	* cube.PosX;
    color += max(-normal.x, 0.0) 	* cube.NegX;
    color += max(normal.y, 0.0) 	* cube.PosY;
    color += max(-normal.y, 0.0) 	* cube.NegY;
    color += max(normal.z, 0.0) 	* cube.PosZ;
    color += max(-normal.z, 0.0) 	* cube.NegZ;
    return color;
}

// Interpolate between 8 probes
vec4 interpolateProbes(vec3 pos, vec3 normal) {
	
	// if pos not inside the cube, return black
	if (pos.x < 0 || pos.y < 0 || pos.z < 0 || pos.x > CUBE_SIZE * 0.1 || pos.y > CUBE_SIZE * 0.1 || pos.z > CUBE_SIZE * 0.1) {
		return vec4(1.0);
	}
	
    vec3 cubePos = pos;
    ivec3 baseIdx = ivec3(floor(cubePos * 10));
    vec3 frac = fract(cubePos * 10);

    vec4 result = vec4(0.0);
    for (int x = 0; x <= 1; ++x) {
        for (int y = 0; y <= 1; ++y) {
            for (int z = 0; z <= 1; ++z) {
                ivec3 offset = ivec3(x, y, z);
                int idx = (baseIdx + offset).z * CUBE_SIZE * CUBE_SIZE + (baseIdx + offset).y * CUBE_SIZE + (baseIdx + offset).x;
                AmbientCube cube = Cubes[idx];
				float occlusion = 0.0f;
                vec4 sampleColor = sampleAmbientCubeHL2(cube, normal, occlusion);
                float weight = (x == 0 ? 1.0 - frac.x : frac.x) *
                               (y == 0 ? 1.0 - frac.y : frac.y) *
                               (z == 0 ? 1.0 - frac.z : frac.z);
				
                result += sampleColor * weight;
            }
        }
    }
    return result;
}

//-----------------------------------------------------------------------------
struct RayPayload
	//-----------------------------------------------------------------------------
{
	// Flag for hit or miss
	uint    IsHit;

	// Geometry instance ids
	int     PrimitiveIndex;
	int     InstanceID;
	int     InstCustIndex;
	// in     int   gl_GeometryIndexEXT;

	// World space parameters
	vec3   RayOrigin;
	vec3   RayDirection;

	// Ray hit info
	float  HitDist;
	bool   IsFrontFacing;

	// Barycentric Coordinates
	vec3    BaryCoords;
};

bool TraceRay(ivec2 ipos, vec3 origin, vec3 direction, vec3 iblColor, inout vec3 bounceColor, inout vec3 illumColor)
{
	rayQueryEXT rayQuery;
	rayQueryInitializeEXT(rayQuery, Scene, gl_RayFlagsNoneEXT, 0xFF, origin, EPS, direction, INF);
	rayQueryProceedEXT(rayQuery);
	if (rayQueryGetIntersectionTypeEXT(rayQuery, true) == gl_RayQueryCommittedIntersectionTriangleEXT  ) {
		RayPayload PayloadData;

		const bool IsCommitted = true;

		PayloadData.PrimitiveIndex = rayQueryGetIntersectionPrimitiveIndexEXT(rayQuery, IsCommitted);
		PayloadData.InstanceID = rayQueryGetIntersectionInstanceIdEXT(rayQuery, IsCommitted);
		PayloadData.InstCustIndex = rayQueryGetIntersectionInstanceCustomIndexEXT(rayQuery, IsCommitted);
		// in     int   gl_GeometryIndexEXT;

		// World space parameters
		PayloadData.RayOrigin  = rayQueryGetWorldRayOriginEXT(rayQuery);
		PayloadData.RayDirection = rayQueryGetWorldRayDirectionEXT(rayQuery);

		// Ray hit info
		// const uint gl_HitKindFrontFacingTriangleEXT = 0xFEU;
		// const uint gl_HitKindBackFacingTriangleEXT = 0xFFU;
		PayloadData.HitDist = rayQueryGetIntersectionTEXT(rayQuery, IsCommitted);
		PayloadData.IsFrontFacing = rayQueryGetIntersectionFrontFaceEXT(rayQuery, IsCommitted);

		mat4x3 worldtoobject = rayQueryGetIntersectionWorldToObjectEXT(rayQuery, IsCommitted);

		// Barycentric Coordinates
		// Floating point barycentric coordinates of current intersection of ray.
		// Three Barycentric coordinates are such that their sum is 1.
		// This gives only two and expects us to calculate the third
		vec2 TwoBaryCoords = rayQueryGetIntersectionBarycentricsEXT(rayQuery, IsCommitted);
		PayloadData.BaryCoords = vec3(1.0 - TwoBaryCoords.x - TwoBaryCoords.y, TwoBaryCoords.x, TwoBaryCoords.y);

		const NodeProxy node = NodeProxies[PayloadData.InstanceID];
		const uvec2 offsets = Offsets[node.modelId];
		const uint indexOffset = offsets.x + PayloadData.PrimitiveIndex * 3;
		const uint vertexOffset = offsets.y;
		const Vertex v0 = UnpackVertex(vertexOffset + Indices[indexOffset]);
		const Vertex v1 = UnpackVertex(vertexOffset + Indices[indexOffset + 1]);
		const Vertex v2 = UnpackVertex(vertexOffset + Indices[indexOffset + 2]);
		const Material material = Materials[node.matId[v0.MaterialIndex]];

		const vec3 normal = normalize((to_world(PayloadData.BaryCoords, v0.Normal, v1.Normal, v2.Normal) * worldtoobject).xyz);
		const vec2 texCoord = Mix(v0.TexCoord, v1.TexCoord, v2.TexCoord, PayloadData.BaryCoords);

		const vec4 texColor = material.DiffuseTextureId >= 0 ? texture(TextureSamplers[nonuniformEXT(material.DiffuseTextureId)], texCoord) : vec4(1);
		const vec4 lightColor = material.MaterialModel == MaterialDiffuseLight ? material.Diffuse : vec4(0);
		
		// 这其实是一个缺省的bounceColor，如果没有取到合适的cache样本，这个bounce的颜色直接乘以穿透的iblcolor不太能是一个好的值
		bounceColor = texColor.rgb * texColor.rgb * material.Diffuse.rgb * iblColor * 0.9;  
		//bounceColor *= vec3(50,0,0);
		illumColor = lightColor.rgb;
		
		vec3 hitPos = origin + direction * PayloadData.HitDist;
		vec4 hpos =  Camera.PrevViewProjection * node.combinedPrevTS * vec4(hitPos, 1);
		ivec2 size = imageSize(MiniGBuffer0);
		ivec2 ipos_new = ivec2((hpos.xy / hpos.w * 0.5 + 0.5) * size);
		if(ipos_new.x < 0 || ipos_new.y < 0 || ipos_new.x > size.x || ipos_new.y > size.y || hpos.z / hpos.w < 0)
		{
			return true;
		}

		vec3 PrevNormal = imageLoad(PrevNormalBuffer, ipos_new).rgb;
		// compare prevnormal and normal
		if(dot(PrevNormal, normal) < 0.5)
		{
			return true;
		}
		
		// 这里从屏幕空间取出DirectLight的信息，IBL和SunLight，但这个hpos不一定是有效的
		bounceColor = imageLoad(InOutDirectLight0, ipos_new).rgb;
		
		return true;
	}
	// miss, hit sky
	return false;
}

#include "common/VertexFunc.glsl"

void main() {

    // checker box
	bool isEvenFrame = Camera.TotalFrames % 2 == 0;
    ivec2 ipos = ivec2(gl_GlobalInvocationID.xy);
	
	ivec2 size = imageSize(MiniGBuffer0);
    uvec2 vBuffer = isEvenFrame ? imageLoad(MiniGBuffer0, ipos).rg : imageLoad(MiniGBuffer1, ipos).rg;
    vec2 uv = vec2(ipos) / vec2(size) * 2.0 - 1.0;
    vec4 origin = Camera.ModelViewInverse * vec4(0, 0, 0, 1);
	vec4 target = Camera.ProjectionInverse * (vec4(uv.x, uv.y, 1, 1));
	vec4 dir = Camera.ModelViewInverse * vec4(normalize(target.xyz), 0);
	vec3 ray_dir = normalize(dir.xyz);
	
	// x == y == 0, hit the sky, quick go
	if(vBuffer.x == 0)
	{
		vec3 iblColor = Camera.HasSky ? equirectangularSample(ray_dir, Camera.SkyRotation).rgb * Camera.SkyIntensity : vec3(0.0);
		imageStore(OutImage, ipos, vec4(iblColor,1));
		imageStore(OutMotionVector, ipos, vec4(0));
		imageStore(InOutDirectLight1, ipos, vec4(0));
		imageStore(OutAlbedoBuffer, ipos, vec4(iblColor,1.0));
		imageStore(OutNormalBuffer, ipos, vec4(0,1,0,1));
		return;
	}

	uvec4 RandomSeed = InitRandomSeed(ipos.x, ipos.y, Camera.TotalFrames);
    
	// visibility fetch hit point, if primary ray, start from here
    Vertex v = get_material_data(ipos, vBuffer, origin.xyz, ray_dir);
	NodeProxy node = NodeProxies[vBuffer.x - 1];
    Material mat = Materials[node.matId[v.MaterialIndex]];
    vec4 albedo = mat.Diffuse;
    if (mat.DiffuseTextureId >= 0)
    {
        vec4 tex = texture(TextureSamplers[mat.DiffuseTextureId], v.TexCoord);
        albedo *= tex * tex;
    }
	
	vec3 normal = normalize( v.Normal.rgb);
	
	// ibl
	const float dotValue = dot(ray_dir, normal);
	const vec3 outwardNormal = dotValue > 0 ? -normal : normal;
	const float cosine = dotValue > 0 ? mat.RefractionIndex * dotValue : -dotValue;
	const float reflectProb = Schlick(cosine, mat.RefractionIndex);
	const float metalProb = mat.Metalness;
	
	
	vec3 irradianceColor = vec3(0);
	vec3 bounceColor = vec3(0);
	uint sampleTimes = Camera.NumberOfSamples;
	
	if (mat.MaterialModel == MaterialDiffuseLight)
	{
		vec3 lightColor = albedo.rgb;
		imageStore(OutImage, ipos, vec4(lightColor,1));
		imageStore(OutMotionVector, ipos, vec4(0));
		imageStore(InOutDirectLight1, ipos, vec4(lightColor,1));
		imageStore(OutAlbedoBuffer, ipos, vec4(lightColor,1.0));
		imageStore(OutNormalBuffer, ipos, vec4(normal,1.0));
		return;
	}

	// calculate the motion vector
	vec4 currFrameHPos = Camera.ViewProjection * vec4(v.Position, 1);
	vec2 currfpos = vec2((currFrameHPos.xy / currFrameHPos.w * 0.5) * vec2(size));

	vec4 prevFrameHPos = Camera.PrevViewProjection * node.combinedPrevTS * vec4(v.Position, 1);
	vec2 prevfpos = vec2((prevFrameHPos.xy / prevFrameHPos.w * 0.5) * vec2(size));
	vec2 motion = prevfpos - currfpos;
	imageStore(OutMotionVector, ipos, vec4(motion,0,0));
	
	// emit ray without any guidance
	for (uint s = 0; s < sampleTimes; ++s)
	{
	    bool chanceReflect = RandomFloat(RandomSeed) < reflectProb;
		const vec3 reflected = reflect( ray_dir, outwardNormal);
		
		const vec3 trace_dir = chanceReflect ? ggxSampling(RandomSeed, mat.Fuzziness, reflected) : 
		(RandomFloat(RandomSeed) < metalProb ? ggxSampling(RandomSeed, mat.Fuzziness, reflected) : 
		mat.MaterialModel != MaterialDielectric ? AlignWithNormal( RandomInHemiSphere1(RandomSeed), outwardNormal ) : ray_dir
		);
		
		vec3 posOffset = vec3(0);
		if(mat.MaterialModel == MaterialDielectric)
		{
			albedo = vec4(1,1,1,1);
			posOffset = ray_dir * 0.1;
		}

		// if miss, sample the sky
		vec3 bounceSingle = vec3(0);
		vec4 albedoSingle = albedo;
		
		if(chanceReflect)
		{
			albedoSingle = vec4(1);
		}
		
		vec3 iblColor = Camera.HasSky ? equirectangularSample(trace_dir , Camera.SkyRotation).rgb * Camera.SkyIntensity : vec3(0.0);
		vec3 illumColor = vec3(0.0);
		bool hit = TraceRay(ipos, v.Position + posOffset, trace_dir, iblColor, bounceSingle, illumColor);
		if(!hit)
		{
			irradianceColor += albedoSingle.rgb * iblColor;
		}
		else
		{
			irradianceColor += albedoSingle.rgb * illumColor;
		}
		bounceColor += albedoSingle.rgb * bounceSingle;
	}
	irradianceColor = irradianceColor / sampleTimes;
	bounceColor = bounceColor / sampleTimes;
	
    vec4 outColor = vec4(irradianceColor,1);
	outColor.a = sampleTimes / Camera.NumberOfSamples;
    
    if(Camera.HasSun)
    {
    	const vec3 lightVector = Camera.SunDirection.xyz;
		vec3 d = max(dot(lightVector, normalize(v.Normal.rgb)),0.0) * Camera.SunColor.xyz * 0.25;
        
        d = mix(d, vec3(0.0), vec3(metalProb));
    
        const vec3 lightVectorCone = AlignWithNormal( RandomInCone(RandomSeed, cos(0.25f / 180.f * M_PI)), lightVector);
        
        rayQueryEXT rayQuery;
        rayQueryInitializeEXT(rayQuery, Scene, gl_RayFlagsTerminateOnFirstHitEXT, 0xFF, v.Position.xyz, EPS, lightVectorCone, INF);
        rayQueryProceedEXT(rayQuery);
        if (rayQueryGetIntersectionTypeEXT(rayQuery, true) == gl_RayQueryCommittedIntersectionTriangleEXT  ) {
            d = vec3(0.0);
        }
        outColor.rgb += albedo.rgb * d;
    }
	
	vec4 directLight = vec4(outColor.rgb, 1);
	
	imageStore(InOutDirectLight1, ipos, directLight);
	imageStore(OutAlbedoBuffer, ipos, albedo);
	imageStore(OutNormalBuffer, ipos, vec4(normal,1.0));
	// with multiple bounceColor
	outColor.rgb += bounceColor.rgb;

	//#if USE_FIREFLY_FILTER
 	 float lum = luminance(outColor.rgb);
	if(lum > 1000.0F)
	{
		outColor.rgb *= 1000.0F / lum;
	}
	//#endif

	// Sample the ambient cube using the normal
	vec4 indirectColor = interpolateProbes(v.Position - CUBE_OFFSET, normal);
	outColor.rgb = indirectColor.rgb;
	
    imageStore(OutImage, ipos, outColor);
}