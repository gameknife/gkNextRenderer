#version 460
#extension GL_GOOGLE_include_directive : require
#include "Platform.glsl"
#include "common/UniformBufferObject.glsl"
#include "common/Const_Func.glsl"

layout(binding = 0, rgba16f) uniform image2D NewSourceImage;
layout(binding = 1, rgba16f) uniform image2D AccumulateImage;
layout(binding = 2, rgba16f) uniform image2D Accumulate1Image;
layout(binding = 3, rg16f) uniform image2D MotionVectorImage;
layout(binding = 4) readonly uniform UniformBufferObjectStruct { UniformBufferObject Camera; };

layout(binding = 5, r32ui) uniform uimage2D VisibilityBuffer;
layout(binding = 6, r32ui) uniform uimage2D Visibility1Buffer;
layout(binding = 7, rgba8) uniform image2D OutImage;

layout(local_size_x = 8, local_size_y = 4, local_size_z = 1) in;

uint FetchPrimitiveIndex(in uint InstanceID)
{
	return (InstanceID >> 16) - 1;
}

bool EdgeDetect(in uint current_primitive_index, in bool isEvenFrame, in ivec2 ipos)
{
	uint center = FetchPrimitiveIndex(current_primitive_index);
	
	uint prev_primitive_index0 = FetchPrimitiveIndex(isEvenFrame ? imageLoad(VisibilityBuffer, ipos + ivec2(2,0)).r : imageLoad(Visibility1Buffer, ipos + ivec2(2,0)).r);
	uint prev_primitive_index1 = FetchPrimitiveIndex(isEvenFrame ? imageLoad(VisibilityBuffer, ipos + ivec2(-2,0)).r : imageLoad(Visibility1Buffer, ipos + ivec2(-2,0)).r);
	uint prev_primitive_index2 = FetchPrimitiveIndex(isEvenFrame ? imageLoad(VisibilityBuffer, ipos + ivec2(0, 2)).r : imageLoad(Visibility1Buffer, ipos + ivec2(0, 2)).r);
	uint prev_primitive_index3 = FetchPrimitiveIndex(isEvenFrame ? imageLoad(VisibilityBuffer, ipos + ivec2(0, -2)).r : imageLoad(Visibility1Buffer, ipos + ivec2(0, -2)).r);

	bool edge0 = any( notEqual( uvec4(prev_primitive_index0, prev_primitive_index1, prev_primitive_index2, prev_primitive_index3), uvec4(center) ));
	bool edge1 = any( equal( uvec4(prev_primitive_index0, prev_primitive_index1, prev_primitive_index2, prev_primitive_index3), uvec4(center) ));

	return edge0 && edge1;
}

// a simple accumulation shader, reproject can impl here later.
void main() {
    ivec2 ipos = ivec2(gl_GlobalInvocationID.xy) + ivec2(Camera.ViewportRect.x, Camera.ViewportRect.y);

    vec4 src = imageLoad(NewSourceImage, ipos);

    bool isEvenFrame = Camera.TotalFrames % 2 == 0 ? true : false;

    bool useHistory = true;
    vec4 final = src;
    vec2 motion = imageLoad(MotionVectorImage, ipos).rg;
	ivec2 previpos = ivec2( floor(ipos + motion) );
	const bool inside = all(lessThan(previpos, ivec2(Camera.ViewportRect.xy + Camera.ViewportRect.zw))) && all(greaterThanEqual(previpos, ivec2(Camera.ViewportRect.xy) + ivec2(-1,-1)));
    const bool check = length(motion) > 0.01 ? true : false;
    // fetch visibility to validate the history
    uint current_primitive_index = isEvenFrame ? imageLoad(VisibilityBuffer, ipos).r : imageLoad(Visibility1Buffer, ipos).r;
    if(Camera.TotalFrames == 0 || !inside)
    {
        useHistory = false;
    }

    if( useHistory )
    {
		if( check )
		{
			uint prev_primitive_index0 = isEvenFrame ? imageLoad(Visibility1Buffer, previpos).r : imageLoad(VisibilityBuffer, previpos).r;
			uint prev_primitive_index1 = isEvenFrame ? imageLoad(Visibility1Buffer, previpos + ivec2(1,0)).r : imageLoad(VisibilityBuffer, previpos + ivec2(1,0)).r;
			uint prev_primitive_index2 = isEvenFrame ? imageLoad(Visibility1Buffer, previpos + ivec2(0,1)).r : imageLoad(VisibilityBuffer, previpos + ivec2(0,1)).r;
			uint prev_primitive_index3 = isEvenFrame ? imageLoad(Visibility1Buffer, previpos + ivec2(1,1)).r : imageLoad(VisibilityBuffer, previpos + ivec2(1,1)).r;

			bool miss = any( notEqual( uvec4(prev_primitive_index0, prev_primitive_index1, prev_primitive_index2, prev_primitive_index3), uvec4(current_primitive_index) ));

			if( miss)
			{
				useHistory = false;
			}
		}

		if(useHistory)
		{
			vec4 history0 = isEvenFrame ? imageLoad(AccumulateImage, previpos) : imageLoad(Accumulate1Image, previpos);
			vec4 history1 = isEvenFrame ? imageLoad(AccumulateImage, previpos + ivec2(1,0)) : imageLoad(Accumulate1Image, previpos + ivec2(1,0));
			vec4 history2 = isEvenFrame ? imageLoad(AccumulateImage, previpos + ivec2(0,1)) : imageLoad(Accumulate1Image, previpos + ivec2(0,1));
			vec4 history3 = isEvenFrame ? imageLoad(AccumulateImage, previpos + ivec2(1,1)) : imageLoad(Accumulate1Image, previpos + ivec2(1,1));

			vec2 subpixel = fract(vec2(ipos) + motion);
			vec4 history = mix(
				mix(history0, history1, subpixel.x),
				mix(history2, history3, subpixel.x),
				subpixel.y
			);

			history = max(vec4(0.0), history);
			// judge current gbuffer / object id with prev frame, to deghosting
			float currKeep = src.w / max(1, Camera.TemporalFrames);
			final = mix(history, src, currKeep);

            // 这里我们希望评估的是噪点密集的区域，就是肉眼看上去十分闪烁的区域
            // 应该类似SVGF一样，评估时间，空间域内的方差
            // 然后，这个评估，也可以用于降噪，这种区域，应该提升降噪强度。
            // 最终的结果，类似于，采样数严重不足的区域，自适应的提升采样数，并拉高后续的降噪强度
            // 而比如光线充足的大平面，采样数足够，后续也可以适当降低降噪强度
            // 我们先输出一个区域的图给到visualdebug	
			if(Camera.AdaptiveSample)
			{
			    // 之前的算法是不稳定，抖动的。使用 delta ^ 2 = prev - cur ^ 2 来预估
			
			    // 将方差直接写入buffer，显示一下，他应该是稳定的
			
				// if history variance is too large, we should not use it.
				const float historyVariance = Camera.AdaptiveVariance;

				float diff = abs(luminance(src.rgb) - luminance(history.rgb));
				if (diff > historyVariance)
				{
					// need sample
					//imageStore(AdaptiveSampleBuffer, ipos, uvec4(Camera.AdaptiveSteps));
				}
			}
		}
    }

    if(isEvenFrame)
    {
        imageStore(Accumulate1Image, ipos, final);
    }
    else
    {
        imageStore(AccumulateImage, ipos, final);
    }

	if(Camera.ShowEdge)
	{
		uint realInstanceId = FetchPrimitiveIndex(current_primitive_index);
		if(realInstanceId == Camera.SelectedId)
		{
			if( EdgeDetect(current_primitive_index, isEvenFrame, ipos ) )
			{
				final.rgb = vec3(1,1,0.05) * Camera.PaperWhiteNit;
			}
		}
	}
	
    imageStore(OutImage, ipos, vec4( final.rgb, 1.0 ));
}